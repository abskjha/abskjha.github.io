---
layout: default
title: Abhishek Jha
---


## News

- **\[Jul 2018\]** Presenting our work on "Speech dependent Lip-sychronization" at 2nd Research Symposium, IIIT Hyderabad.

- **\[May 2018\]** Short paper "Lip-Synchronization for Dubbed Instructional Videos" accepted at [CVPR 2018 Workshop (FIVER)](http://fiver.eecs.umich.edu/).

- **\[May 2018\]** Giving a talk on "[Introduction to Image Style Transfer](/data/intro_to_photorealistic_Image_stylization.pdf)", at [CVIT](http://cvit.iiit.ac.in), IIIT Hyderabad.

- **\[May 2018\]** Paper "Cross-Modal Style Transfer" accepted at [ICIP](https://2018.ieeeicip.org/).

- **\[Apr 2018\]** Presenting our work on "Word-spotting in Silent Lip videos", at 1st Research Symposium, IIIT Hyderabad.

- **\[Mar 2018\]** Presenting our paper "Word-spotting in Silent Lip videos", at [WACV 2018](http://wacv18.wacv.net/), Lake Tahoe, CA.

- **\[Fab 2018\]** Organizing annual [R&D Showcase 2018](https://iiit.ac.in/randd/), at IIIT Hyderabad.

- **\[Jan 2018\]** Will be working as a "Mentor" [for Foundations of Artificial Intelligence and Machine Learning](https://www.talentsprint.com/aiml.dpl).


## Bio

I am a Computer Science MS student at IIIT Hyderabad. I am advised by [Prof. C. V. Jawahar](http://faculty.iiit.ac.in/~jawahar/) and co-advised by [Prof. Vinay P. Namboodiri](https://www.cse.iitk.ac.in/users/vinaypn/) at [Center for Visual Information Technology](http://cvit.iiit.ac.in/).

My research focuses on computer vision and machine learning for solving Visual Speech Recognition (VSR) which lies at the intersection of multiple modalities like videos (speech videos) audios (speech audio) and texts (Natural language).  I have also worked in the space of Image stylization for enabling cross-modal transfer of style. My goal is to develope robust and scalable solutions for real world sensing problems using computer vision.


Prior to this, I have spent one year (2015-16) as a research fellow at CVIT working on a problem on cross-modal multimedia retrieval, under the supervision of Prof. Jawahar. Before moving to Hyderabad, I was a Manager, Planning at [Tata Steel Limited](http://tatasteel.com/) (2014-15) working towards automation and energy consumption optimization in processing plant.

I graduated from [IIT Dhanbad](http://iitism.ac.in), India, in 2014 with a B.Tech in Electronics and Communication Engineering. During my undergraduate years I worked closely with Prof. Mrinal Sen and [Dr. Dilip Prasad](https://sites.google.com/site/dilipprasad/) on projects related to computer vision and robotics.




## Publications

<!---
1. Abhishek Jha, Vikram Voleti, Vinay Namboodiri and C.V. Jawahar, ”Lip-Synchronization for Dubbed Instructional Videos”, Fine-grained Instructional Video Understanding, CVPR Workshop 2018. \[[Paper](http://fiver.eecs.umich.edu/abstracts/CVPRW_2018_FIVER_A_Jha.pdf)\] \[[Poster](https://drive.google.com/file/d/19eTyXoDtKo_txxRRylg0mM9oQS7iKVaQ/view?usp=sharing)\]


2. Sahil Chelaramani, Abhishek Jha and Anoop Namboodiri, ”Cross-modal style transfer”, 25th IEEE International Conference on Image Processing (ICIP) 2018. \[[Paper](https://drive.google.com/file/d/1lT8HNGrsUio9MW87XNattaUz5hsBkXYO/view?usp=sharing)\]


3. Abhishek  Jha,  Vinay  Namboodiri  and  C.V.  Jawahar,  ”Word  Spotting  in  Silent  Lip  Videos”,  IEEE  Winter
Conference on Applications of Computer Vision (WACV) 2018. \[[Paper](https://cvit.iiit.ac.in/images/ConferencePapers/2018/Word-Spotting-in-Silent-Lip-Videos.pdf)\] \[[Poster](https://drive.google.com/file/d/1XAE6gRhy2terH2DOmg87uEzpXzSDZgTk/view?usp=sharing)\] \[[Project page](https://cvit.iiit.ac.in/research/projects/cvit-projects/lip-word-spotting)\]


4. Yashaswi Verma, Abhishek Jha, C.V. Jawahar, ”Cross-specificity:  modelling data semantics for cross-modal
matching and retrieval”, International Journal of Multimedia Information Retrieval, Springer, June 2018. \[[Link](https://link.springer.com/article/10.1007/s13735-017-0138-7)\]
-->



<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" style="border-style: none">

<tbody>
	<tr>
		<td width="25%"><img src="/images/cvpr_w_2018.png" alt="Visual_dub" width="250" style="border-style: none"></td>
		<td width="75%" valign="top">
			<p>
				<a href="http://fiver.eecs.umich.edu/abstracts/CVPRW_2018_FIVER_A_Jha.pdf">Lip-Synchronization for Dubbed Instructional Videos</a> <br>
				<strong>Abhishek Jha</strong>,
				Vikram Voleti,
				<a href="https://www.cse.iitk.ac.in/users/vinaypn/">Vinay P. Namboodiri</a>,
				<a href="https://www.cc.gatech.edu/~slee3191/">C. V. Jawahar</a> <br>
			<span style="color:#9A2617;">FIVER, <strong>CVPR Workshop</strong> 2018</span>
				<br><br>
				<a href="http://fiver.eecs.umich.edu/abstracts/CVPRW_2018_FIVER_A_Jha.pdf">[Short Paper]</a> <a href="https://drive.google.com/file/d/19eTyXoDtKo_txxRRylg0mM9oQS7iKVaQ/view?usp=sharing">[Poster]</a>
			</p>
		</td>
		
	</tr>		
</tbody>



<tbody>
	<tr>
		<td width="25%"><img src="/images/icip_2018_3.png" alt="Visual_dub" width="250" style="border-style: none"></td>
		<td width="75%" valign="top">
			<p>
				<a href="https://drive.google.com/file/d/1lT8HNGrsUio9MW87XNattaUz5hsBkXYO/view?usp=sharing">Cross-modal style transfer</a> <br>
				Sahil Chelaramani,
				<strong>Abhishek Jha</strong>,
				<a href="https://faculty.iiit.ac.in/~anoop/">Anoop Namboodiri</a><br>
			<span style="color:#9A2617;">IEEE International Conference on Image Processing <strong>(ICIP)</strong> 2018</span>
				
				<br><br>
				<a href="https://drive.google.com/file/d/1lT8HNGrsUio9MW87XNattaUz5hsBkXYO/view?usp=sharing">[Paper]</a>
			</p>
		</td>
		
	</tr>		
</tbody>







<tbody>
	<tr>
		<td width="25%"><img src="/images/wacv_2018.png" alt="Visual_dub" width="250" style="border-style: none"></td>
		<td width="75%" valign="top">
			<p>
				<a href="https://cvit.iiit.ac.in/images/ConferencePapers/2018/Word-Spotting-in-Silent-Lip-Videos.pdf">Word Spotting in Silent Lip Videos</a> <br>
				<strong>Abhishek Jha</strong>,
				<a href="https://www.cse.iitk.ac.in/users/vinaypn/">Vinay P. Namboodiri</a>,
				<a href="https://www.cc.gatech.edu/~slee3191/">C. V. Jawahar</a> <br>
			<span style="color:#9A2617;">IEEE  Winter Conference on Applications of Computer Vision <strong>(WACV)</strong> 2018</span>
				<br><br>
				<a href="https://cvit.iiit.ac.in/images/ConferencePapers/2018/Word-Spotting-in-Silent-Lip-Videos.pdf">[Paper]</a> <a href="https://drive.google.com/file/d/1XAE6gRhy2terH2DOmg87uEzpXzSDZgTk/view?usp=sharing">[Poster]</a> <a href="https://cvit.iiit.ac.in/research/projects/cvit-projects/lip-word-spotting">[Project Page]</a>
			</p>
		</td>
		
	</tr>		
</tbody>


<tbody>
	<tr>
		<td width="25%"><img src="/images/IJMIR_2018.png" alt="Visual_dub" width="250" style="border-style: none"></td>
		<td width="75%" valign="top">
			<p>
				<a href="https://link.springer.com/article/10.1007/s13735-017-0138-7">Cross-specificity:  modelling data semantics for cross-modal
matching and retrieval</a> <br>
				Yashaswi Verma,
				<strong>Abhishek Jha</strong>,
				<a href="https://www.cc.gatech.edu/~slee3191/">C. V. Jawahar</a> <br>
			<span style="color:#9A2617;">International Journal of Multimedia Information Retrieval, Springer, June 2018</span>
				<br><br>
				<a href="https://link.springer.com/article/10.1007/s13735-017-0138-7">[Link]</a>
			</p>
		</td>
		
	</tr>		
</tbody>






</table>































<!---
## Typography

# This is a [**link**](http://google.com). Something *italics* and something **bold**.

Here is a table

Year | Award | Category
-----|-------|--------
2014 | Emmy  | Won Outstanding Lead Actor in a miniseries or a movie
2015 | BAFTA | Nominated for Best Leading Actor for Sherlock
2014 | Satellite | Won Best Actor miniseries or television film

Here is a horizontal rule

---

Here is a blockquote

> To a great mind, nothing is little

## References

* Foo Bar: Head of Department, Placeholder Names, Lorem
* John Doe: Associate Professor, Department of Computer Science, Ipsum
-->
