---
layout: default
is_contact: true
---

## Projects

<h3> 1. Audio Visual Speech Recognition and Synthesis </h3>

<img class="img_custom" src="images/vsr_synth.jpg" width="400" align="right" padding ="10px"/>

<div style="font-size:12px;">

<strong>Guide</strong>: Prof. C. V. Jawahar and Prof. Vinay P. Namboodiri.

Speech is a multi-modal process, and lip-motion palys a major role in it (See <a href="https://www.youtube.com/watch?v=G-lN8vWm3m0">McGurk effect</a>. Predicting what has been said just by looking at the speakerâ€™s lips can be a boon for a host of application from augmenting audio speech in the medium where the audio noise is significantly limiting the speech, to assisting deaf and other people suffering from auditory disabilities.

On the other hand, we also propose a 'Visual-dubbing' method which re-synchronizes the lips of speaking characters in the foregoing language speech video according to the native language dubbing audio.

</div>

**Related Publications:**

<div style="font-size:12px;">
<ol class="c">
<li>Abhishek Jha, Vinay Namboodiri and C.V. Jawahar, <strong>Word Spotting in Silent Lip Videos</strong>, IEEE Winter Conference on Applications of Computer Vision (WACV 2018), Lake Tahoe, CA, USA, 2018. <a href="https://cvit.iiit.ac.in/images/ConferencePapers/2018/Word-Spotting-in-Silent-Lip-Videos.pdf">[PDF]</a></li>

<li>Abhishek Jha, Vikram Voleti, Vinay Namboodiri and C.V. Jawahar, <strong>Lip-Synchronization for Dubbed Instructional Videos</strong>, Fine-grained Instructional Video undERstanding (FIVER), CVPR Workshop, Salt Lake City, Utah, USA, 2018. <a href="http://fiver.eecs.umich.edu/abstracts/CVPRW_2018_FIVER_A_Jha.pdf">[PDF]</a></li>
</ol>
</div>
